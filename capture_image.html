<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Hello OpenCV.js</title>
  </head>
  <body>
    <video id="videoInput" width="800" height="600"></video>
    <canvas id="canvasOutput"></canvas>
    <script type="text/javascript">
      function onOpenCvReady() {
        const IM_WIDTH = 800
        const IM_HEIGHT = 600 

        const RANK_WIDTH = 400;
        const RANK_HEIGHT = 580;

        const SUIT_WIDTH = 70;
        const SUIT_HEIGHT = 100;

        // Adaptive threshold levels
        const BKG_THRESH = 60
        const CARD_THRESH = 30

        const FPS = 30;

        let video = document.getElementById("videoInput"); 
        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then(function(stream) {
                video.srcObject = stream;
                video.play();
            })
            .catch(function(err) {
                console.log("An error occured! " + err);
            });

        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
        let cap = new cv.VideoCapture(video);

        function processVideo() {
          let begin = Date.now();
          cap.read(src);

          let thresh = preprocessImage(src);

          let contours = new cv.MatVector();
          let hierarchy = new cv.Mat();
          cv.findContours(thresh, contours, hierarchy, cv.RETR_TREE,cv.CHAIN_APPROX_SIMPLE)

          var largestContour = null;
          var largestArea = 0;
          for (let i = 0; i < contours.size(); ++i) {
            let c = contours.get(i);
            let area = cv.contourArea(c, false);
            if (area > largestArea) {
              largestArea = area;
              largestContour = c;
            }
          }

          if (largestContour != null) {
            let peri = cv.arcLength(largestContour,true);
            let approx = new cv.Mat();
            cv.approxPolyDP(largestContour, approx, 0.01*peri,true);
            let pts = nj.float32(approx);

            let rect = cv.boundingRect(largestContour);
            let x = rect.x;
            let y = rect.y;
            let width = rect.width;
            let height = rect.height;

            let warp = flattener(src, pts, width, height);
          }

          cv.imshow('canvasOutput', thresh);

          // schedule next one.
          let delay = 1000/FPS - (Date.now() - begin);
          setTimeout(processVideo, delay);
          }
        setTimeout(processVideo, 0);

        function preprocessImage(image, white = false) {
          let gray = new cv.Mat(video.height, video.width, cv.CV_8UC4);
          let blur = new cv.Mat(video.height, video.width, cv.CV_8UC4);
          let thresh = new cv.Mat(video.height, video.width, cv.CV_8UC4);
          cv.cvtColor(image, dst, cv.COLOR_BGR2GRAY);
          cv.bitwise_not(dst, gray);
          cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0, 0, cv.BORDER_DEFAULT);

          // The best threshold level depends on the ambient lighting conditions.
          // For bright lighting, a high threshold must be used to isolate the cards
          // from the background. For dim lighting, a low threshold must be used.
          // To make the card detector independent of lighting conditions, the
          // following adaptive threshold method is used.
          
          // A background pixel in the center top of the image is sampled to determine
          // its intensity. The adaptive threshold is set at 50 (THRESH_ADDER) higher
          // than that. This allows the threshold to adapt to the lighting conditions.
          // let a = new nj.array(image.data);
          let bkg_level = gray.data[(gray.cols / 25) * (gray.rows / 2)];
          let thresh_level = bkg_level + BKG_THRESH;

          if(white = true && thresh_level < 110) {
            thresh_level = 110;
          }

          cv.threshold(blur, thresh, thresh_level, 255, cv.THRESH_BINARY);
          return thresh;
        }

        function flattener(image, pts, w, h) {
          // Flattens an image of a card into a top-down 200x300 perspective.
          // Returns the flattened, re-sized, grayed image.
          // See www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/
          let temp_rect = nj.zeros((4,2), 'float32');
          let s = nj.sum(pts, axis=2);
          console.log(s);
        }

      }
    </script>
    <script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
    <script src="bower_components/numjs/dist/numjs.min.js"></script>
  </body>
</html>